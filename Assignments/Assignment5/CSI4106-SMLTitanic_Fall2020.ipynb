{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5 - Titanic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI4106 Artificial Intelligence  \n",
    "Fall 2020  \n",
    "Prepared by Julian Templeton and Caroline Barri√®re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***INTRODUCTION***:\n",
    "\n",
    "The supervised classification task tackled in this notebook is to determine whether a passenger survived or did not survive on the Titanic. This is a common introductory problem to supervised machine learning and is a challenge on a popular site called Kaggle. Kaggle contains competitions that users can compete in. These competitions typical provide a dataset to work with and a description of the problem to solve. That said, not all datasets will include the ground truth for the test set. Or, a competition may only provide a training and validation set, not the test set. This means that users will not know how their models perform on the real unseen data until the host(s) test the user's submission on the private test set, posting the results.    \n",
    "\n",
    "This notebook will expand your knowledge from the previous notebook and will introduce the concept of dealing with class imabalance through the use of a technique called oversampling. You will also see how a dataset can have issues with its data and that not every feature should be used to train and test a model. You will also perform the training, testing, and evaluation in slightly new ways since we will be working with a different type of dataset.\n",
    "\n",
    "Once again, this notebook uses **scikit-learn** (http://scikit-learn.org/stable/), **Matplot**, **Numpy**, and **Pandas**. However, we will also be using **imblearn** which provides robust techniques for balancing the number of instances of different classes. To install this packge, use the command ***pip install imbalanced-learn***. If this causes any issues you can also try *pip install imblearn*.\n",
    "\n",
    "In this notebook we will use the Naive Bayes algorithm and the Logistic Regression algorithm to perform the classification for this problem. After evaluating both models, you will determine which performed better, and why. Finally, you will go through the process once more to determine whether or not a common oversampling technique will improve the results obtained.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***HOMEWORK***:  \n",
    "Go through the notebook by running each cell, one at a time.  \n",
    "Look for **(TO DO)** for the tasks that you need to perform. Do not edit the code outside of the questions which you are asked to answer unless specifically asked. Once you're done, Sign the notebook (at the end of the notebook), and submit it.  \n",
    "\n",
    "*The notebook will be marked on 30.  \n",
    "Each **(TO DO)** has a number of points associated with it.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Exploring the dataset**    \n",
    "\n",
    "First, we will set up the data that we will be working with. This data is included with the notebook and can be found from Kaggle, which also contains a description of the data that we will be working with (https://www.kaggle.com/c/titanic/data). It is highly recommended that you take a quick look at the Data Dictionary within the Overview section that is available by the link above. This will help you understand the data that we will be working with.     \n",
    "\n",
    "As alluded to in the introduction, this Kaggle competition only provides annotated training data, while the testing data is unannotated. The ground truth of the the test dataset can be found online, but we will focus on only using the training dataset to create and test our model. This will provide a different type of Machine Learning experiment process for you to go through.       \n",
    "\n",
    "There are many cases where a competition will only give a training set, so we will try to learn whether a passenger did or did not survive on the Titanic from this training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages for data analysis and machine learning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the training dataset (*train.csv*) into a dataframe with Pandas and explore the first ten samples. Notice that this dataset contains a variety of potential features, unlike the movie reviews that we worked with last notebook which contained movie reviews that we had to transform. This dataset contains both continuous and discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see a variety of columns. Out of these columns, the ***Survived*** column represents the class values that we wish to predict. A passenger survived from the Titanic if *Survived* is 1 and did not survive from the Titanic if *Survived* is 0. These are our two classes that we will predict (1 and 0). The other columns represent potential features that can be used by the Machine Learning algorithms to learn how to accurately predict the target class.   \n",
    "\n",
    "One important note from the data above is that not every sample contains data for each column. For example, Passenger 6 (Moran, Mr. James) does not contain a value for their *Age* and does not contain the *Cabin* that they were residing in. Since Machine Learning algorithms learn from data, a Data Scientist will need to learn how to accurately fill in the missing data. Robust methods of doing this is beyond the scope of this notebook, but we will be filling in most of the missing data later on through simple means.    \n",
    "\n",
    "Another note is that it is important to consider whether one class is seen more frequently than another class within the data. A class with the most instances is called the *majority* class and a class with least instances is called the *minority* class. If one class contains more instances than another class, the algorithm may focus on learning that majority class more than the minority class. In problems such as cancer diagnosis, this is a major problem (since many more people do not have cancer). Thus, another issue that we will explore in this notebook is the concept of using oversampling  to balance the class distribution. This concept will be explained in detail later in the notebook.  \n",
    "\n",
    "Below is a plot of the number of instances for each class. In this scenario, based on the data available from the training set, more people did not survive on the Titanic than those who did survive (as we would expect in this scenario). Since we cannot simply collect more data on passenger's who survived the Titanic, we will need to think of ways to balance the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEFCAYAAAAYKqc0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARfklEQVR4nO3de5DdZX3H8fenIFpFBWRByMXQMVaxrcpEpdXpoDgqeAmdyoxoMVJsakdntGoVnVpltAptpzrajh0qloByK16ISK0MiNYbEhBRjErKcFlDIZSLImoFv/3jPCuHzdnsSbKbTR7er5md83ue33Oe3/ecbD7nd579nd1UFZKkvvzGQhcgSZp7hrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd+10kvxLknfOw7zvTvLx7Zzj7iS/NUf1vCPJR9v2siSVZPc5mntpq3W3uZhPux7DXWNJ8uwkX0tyV5Lbk3w1ydPn41hV9dqqes98zD2TJIcl+VULxLuTTCY5d/pjrKo9q+q6MeaanO2YVfW+qnrN9tbejnl9kucNzX1jq/W+uZhfux7DXbNK8ijgAuDDwD7AIuBE4BfbMFeS7Kzfdxurak/gkcChwPeB/0py+FwfaK7O0KWZ7Kz/ybRzeQJAVZ1VVfdV1c+q6gtVdTVsvtwxfYkhyaVJ/jbJV4F7gHckWTd8gCR/mWRt2z4tyXvb9vokLx4at3uS25Ic0tqHtncUdyb5dpLDhsYelORLSX6S5CJg33EebA1MVtXfAB8FTh6as5I8vm0fmeR7bf4fJXlLkkcA/wEcOPQu4MD2HJ2X5ONJfgy8eoZloj9NsjHJzUnePHTcXz8nrf3rdwdJzgCWAp9tx3vriH+DA5Osbe+6NiT5s6G53t3epZzeHss1SVaM81xp52W4axw/BO5LsibJEUn23oY5jgVWMzgr/jDw20mWD+1/BXDmiPudBRwz1H4BcFtVXZlkEfA54L0M3lG8Bfhkkok29kzgCgah/h5g1TbU/SngkBba050K/HlVPRL4HeCSqvopcATtXUD72tjGrwTOA/YCPjHD8Z4DLAeeD5wwvNQyk6o6FrgReEk73t+NGHYWMAkcCLwMeN+0dyQvBc5uta0F/mm242rnZrhrVlX1Y+DZQAH/CmxqZ4H7b8U0p1XVNVV1b1XdBZxPC+0W8k9kECrTnQm8NMnDW3v4ReBPgAur6sKq+lVVXQSsA45MshR4OvDOqvpFVX0Z+OzWPO5mIxAGoTfdL4GDkzyqqu6oqitnmevrVfWZVuvPZhhzYlX9tKq+A/wbD3xh2yZJljD493tbVf28qq5i8I7k2KFhX2nP433AGcBTtve4WliGu8ZSVeur6tVVtZjBWeqBwAe3YoqbprXP5P7gegXwmaq6Z8RxNwDrgZe0gH8p94f744Cj25LMnUnuZBBiB7T67mhn0lNu2Ip6pyxi8KJ254h9fwwcCdzQln9+f5a5pj8Hs425gcHj2F4HArdX1U+mzb1oqP0/Q9v3AA/z5wK7NsNdW62qvg+cxiDkAX4KPHxoyGNH3W1a+wvAvkmeyiDkRy3JTJlamlkJfK8FPgyC8Iyq2mvo6xFVdRJwM7D3tOWUpbM/us38EXDltBeJwQOquryqVgL7AZ8Bzp3aNcNc4/wK1iVD20sZvHOA2Z/jLc29EdgnySOnzf2jMerRLspw16ySPDHJm5Msbu0lDML2G23IVcAfZnBt9aOBt882Z1Xdy2D9+e8ZrJdftIXhZzNYg/4LHvgi8HEGZ/QvSLJbkoe1HzQurqobGCzRnJhkjyTPBl4y5uNNkkVJ3gW8BnjHiDF7JHllkkdX1S+BHwNTlx3eAjymPRdb651JHp7kycBxwDmt/yoGy037JHks8MZp97sFGHn9fVXdBHwNeH97jn4POJ6Z1/3VAcNd4/gJ8EzgsiQ/ZRDq3wXeDNDWus8BrmbwA8wLxpz3TOB5wL+3sB+pqm4Gvg78AfeH3VRorWQQvpsYnMn/Ffd/X7+i1X078C7g9FnqOTDJ3cDdwOXA7wKHVdUXZhh/LHB9u/rltQx+BjD1zuYs4Lq2XLQ1SytfAjYAFwP/MHTsM4BvA9czeNdzzrT7vR/463a8t4yY9xhgGYOz+E8D72r/bupU/GMdktQfz9wlqUOGuyR1yHCXpA4Z7pLUIcNdkjq0U3wCbd99961ly5YtdBmStEu54oorbquqiVH7dopwX7ZsGevWrZt9oCTp15LM+Cs1XJaRpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWin+BDTrmLZCZ9b6BK6cv1JL1roEqRueeYuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjo0VrgnuT7Jd5JclWRd69snyUVJrm23e7f+JPlQkg1Jrk5yyHw+AEnS5rbmzP05VfXUqlrR2icAF1fVcuDi1gY4AljevlYDH5mrYiVJ49meZZmVwJq2vQY4aqj/9Br4BrBXkgO24ziSpK00brgX8IUkVyRZ3fr2r6qbAdrtfq1/EXDT0H0nW58kaQcZ98/sPauqNibZD7goyfe3MDYj+mqzQYMXidUAS5cuHbMMSdI4xjpzr6qN7fZW4NPAM4BbppZb2u2tbfgksGTo7ouBjSPmPKWqVlTViomJiW1/BJKkzcwa7kkekeSRU9vA84HvAmuBVW3YKuD8tr0WeFW7auZQ4K6p5RtJ0o4xzrLM/sCnk0yNP7OqPp/kcuDcJMcDNwJHt/EXAkcCG4B7gOPmvGpJ0hbNGu5VdR3wlBH9/wscPqK/gNfNSXWSpG3iJ1QlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjo0drgn2S3Jt5Jc0NoHJbksybVJzkmyR+t/aGtvaPuXzU/pkqSZbM2Z+xuA9UPtk4EPVNVy4A7g+NZ/PHBHVT0e+EAbJ0nagcYK9ySLgRcBH23tAM8FzmtD1gBHte2VrU3bf3gbL0naQcY9c/8g8FbgV639GODOqrq3tSeBRW17EXATQNt/VxsvSdpBZg33JC8Gbq2qK4a7RwytMfYNz7s6ybok6zZt2jRWsZKk8Yxz5v4s4KVJrgfOZrAc80FgryS7tzGLgY1texJYAtD2Pxq4ffqkVXVKVa2oqhUTExPb9SAkSQ80a7hX1duranFVLQNeDlxSVa8Evgi8rA1bBZzftte2Nm3/JVW12Zm7JGn+bM917m8D3pRkA4M19VNb/6nAY1r/m4ATtq9ESdLW2n32IferqkuBS9v2dcAzRoz5OXD0HNQmSdpGfkJVkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktShrfpjHZJ2TstO+NxCl9CV60960UKXsN08c5ekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjo0a7gneViSbyb5dpJrkpzY+g9KclmSa5Ock2SP1v/Q1t7Q9i+b34cgSZpunDP3XwDPraqnAE8FXpjkUOBk4ANVtRy4Azi+jT8euKOqHg98oI2TJO1As4Z7Ddzdmg9pXwU8Fziv9a8BjmrbK1ubtv/wJJmziiVJsxprzT3JbkmuAm4FLgL+G7izqu5tQyaBRW17EXATQNt/F/CYuSxakrRlY4V7Vd1XVU8FFgPPAJ40ali7HXWWXtM7kqxOsi7Juk2bNo1bryRpDFt1tUxV3QlcChwK7JVk6o99LAY2tu1JYAlA2/9o4PYRc51SVSuqasXExMS2VS9JGmmcq2UmkuzVtn8TeB6wHvgi8LI2bBVwftte29q0/ZdU1WZn7pKk+TPOn9k7AFiTZDcGLwbnVtUFSb4HnJ3kvcC3gFPb+FOBM5JsYHDG/vJ5qFuStAWzhntVXQ08bUT/dQzW36f3/xw4ek6qkyRtEz+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUoVnDPcmSJF9Msj7JNUne0Pr3SXJRkmvb7d6tP0k+lGRDkquTHDLfD0KS9EDjnLnfC7y5qp4EHAq8LsnBwAnAxVW1HLi4tQGOAJa3r9XAR+a8aknSFs0a7lV1c1Vd2bZ/AqwHFgErgTVt2BrgqLa9Eji9Br4B7JXkgDmvXJI0o61ac0+yDHgacBmwf1XdDIMXAGC/NmwRcNPQ3SZbnyRpBxk73JPsCXwSeGNV/XhLQ0f01Yj5VidZl2Tdpk2bxi1DkjSGscI9yUMYBPsnqupTrfuWqeWWdntr658ElgzdfTGwcfqcVXVKVa2oqhUTExPbWr8kaYRxrpYJcCqwvqr+cWjXWmBV214FnD/U/6p21cyhwF1TyzeSpB1j9zHGPAs4FvhOkqta3zuAk4BzkxwP3Agc3fZdCBwJbADuAY6b04olSbOaNdyr6iuMXkcHOHzE+AJet511SZK2g59QlaQOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0KzhnuRjSW5N8t2hvn2SXJTk2na7d+tPkg8l2ZDk6iSHzGfxkqTRxjlzPw144bS+E4CLq2o5cHFrAxwBLG9fq4GPzE2ZkqStMWu4V9WXgdunda8E1rTtNcBRQ/2n18A3gL2SHDBXxUqSxrOta+77V9XNAO12v9a/CLhpaNxk65Mk7UBz/QPVjOirkQOT1UnWJVm3adOmOS5Dkh7ctjXcb5labmm3t7b+SWDJ0LjFwMZRE1TVKVW1oqpWTExMbGMZkqRRtjXc1wKr2vYq4Pyh/le1q2YOBe6aWr6RJO04u882IMlZwGHAvkkmgXcBJwHnJjkeuBE4ug2/EDgS2ADcAxw3DzVLkmYxa7hX1TEz7Dp8xNgCXre9RUmSto+fUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tC8hHuSFyb5QZINSU6Yj2NIkmY25+GeZDfgn4EjgIOBY5IcPNfHkSTNbD7O3J8BbKiq66rq/4CzgZXzcBxJ0gx2n4c5FwE3DbUngWdOH5RkNbC6Ne9O8oN5qOXBal/gtoUuYjY5eaEr0ALwe3NuPW6mHfMR7hnRV5t1VJ0CnDIPx3/QS7KuqlYsdB3SdH5v7jjzsSwzCSwZai8GNs7DcSRJM5iPcL8cWJ7koCR7AC8H1s7DcSRJM5jzZZmqujfJ64H/BHYDPlZV18z1cbRFLndpZ+X35g6Sqs2WwyVJuzg/oSpJHTLcJalDhrskdWg+rnPXDpTkiQw+AbyIwecJNgJrq2r9ghYmaUF55r4LS/I2Br/eIcA3GVyGGuAsf2GbdmZJjlvoGnrn1TK7sCQ/BJ5cVb+c1r8HcE1VLV+YyqQtS3JjVS1d6Dp65rLMru1XwIHADdP6D2j7pAWT5OqZdgH778haHowM913bG4GLk1zL/b+sbSnweOD1C1aVNLA/8ALgjmn9Ab6248t5cDHcd2FV9fkkT2Dwa5YXMfhPMwlcXlX3LWhxElwA7FlVV03fkeTSHV/Og4tr7pLUIa+WkaQOGe6S1CHDXZI6ZLhLUocMd0nq0P8DLTWQidll2sYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure() # Creates a new figure\n",
    "X[\"Survived\"].value_counts().plot(kind=\"bar\", title=\"Survived Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in mind, we will now move the class values from the pandas dataframe X into a numpy array called y. X is typically used to refer to the features and y is typically used to represent the class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can ONLY BE DONE ONCE, as we pop the values into a new variable to be used as predicted class\n",
    "y = X.pop(\"Survived\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have taken a look into the class distribution, we will now take a look into the other attributes available in the dataset. Below we print a list of all available attributes and explore the properties of the *Embarked* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "(891, 11)\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show all attributes\n",
    "print(list(X))\n",
    "# Examples of data exploration\n",
    "print(X.shape)\n",
    "print(X['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above notice, it can be seen that the *Embarked* attribute contains 644 *S* values, 168 *C* values, and 77 *Q* values. But this is actually two less than the total of 891 instances. Thus, there are two missing values within this attribute. This is shown via the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                       Name     Sex  \\\n",
       "61            62       1                        Icard, Miss. Amelie  female   \n",
       "829          830       1  Stone, Mrs. George Nelson (Martha Evelyn)  female   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "61   38.0      0      0  113572  80.0   B28      NaN  \n",
       "829  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the rows with a null Embarked value\n",
    "X[X['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q1 - 2 marks**   \n",
    "Based on the above example, explore the *Age* and the *Cabin* attributes. Print which values they contain and the rows where they are missing values. Note that some values may not be explicitly shown when called (represented by ...), so as long as the first few and last few rows appear that is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Sex_female', 'Sex_male', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
      "(891, 10)\n",
      "29.699118    177\n",
      "24.000000     30\n",
      "22.000000     27\n",
      "18.000000     26\n",
      "28.000000     25\n",
      "            ... \n",
      "55.500000      1\n",
      "53.000000      1\n",
      "20.500000      1\n",
      "23.500000      1\n",
      "0.420000       1\n",
      "Name: Age, Length: 89, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Pclass, Sex_female, Sex_male, Age, SibSp, Parch, Fare, Embarked_C, Embarked_Q, Embarked_S]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Q1: For the Age attribute\n",
    "print(list(X))\n",
    "print(X.shape)\n",
    "print(X['Age'].value_counts())\n",
    "X[X['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "(891, 11)\n",
      "B96 B98        4\n",
      "C23 C25 C27    4\n",
      "G6             4\n",
      "F2             3\n",
      "D              3\n",
      "              ..\n",
      "A10            1\n",
      "A16            1\n",
      "T              1\n",
      "E17            1\n",
      "D6             1\n",
      "Name: Cabin, Length: 147, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>687 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                      Name     Sex  \\\n",
       "0              1       3                   Braund, Mr. Owen Harris    male   \n",
       "2              3       3                    Heikkinen, Miss. Laina  female   \n",
       "4              5       3                  Allen, Mr. William Henry    male   \n",
       "5              6       3                          Moran, Mr. James    male   \n",
       "7              8       3            Palsson, Master. Gosta Leonard    male   \n",
       "..           ...     ...                                       ...     ...   \n",
       "884          885       3                    Sutehall, Mr. Henry Jr    male   \n",
       "885          886       3      Rice, Mrs. William (Margaret Norton)  female   \n",
       "886          887       2                     Montvila, Rev. Juozas    male   \n",
       "888          889       3  Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
       "890          891       3                       Dooley, Mr. Patrick    male   \n",
       "\n",
       "      Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "2    26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4    35.0      0      0            373450   8.0500   NaN        S  \n",
       "5     NaN      0      0            330877   8.4583   NaN        Q  \n",
       "7     2.0      3      1            349909  21.0750   NaN        S  \n",
       "..    ...    ...    ...               ...      ...   ...      ...  \n",
       "884  25.0      0      0   SOTON/OQ 392076   7.0500   NaN        S  \n",
       "885  39.0      0      5            382652  29.1250   NaN        Q  \n",
       "886  27.0      0      0            211536  13.0000   NaN        S  \n",
       "888   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "890  32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[687 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Q1: For the Cabin attribute\n",
    "print(list(X))\n",
    "print(X.shape)\n",
    "print(X['Cabin'].value_counts())\n",
    "X[X['Cabin'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cleaning the data**    \n",
    "\n",
    "Having explored the dataset, we will now work on cleaning some of the missing values from attributes that we will be using as features for the Machine Learning algorithms.   \n",
    "\n",
    "Specifically, we will fill in the missing values for the *Age* and *Embarked* attributes. Although it is also possible to do this for the *Cabin* attribute, this attribute requires additional care when filling in its missing values. Thus, this notebook will not be exploring the *Cabin* attribute despite its importance (since the location of the passenger is an important identifier as to whether they survived or did not survive).   \n",
    "\n",
    "When determining how to fill in the missing values, we will be considering the mean value of the attribute itself or of other attributes to fill in the missing values. However, more robust methods can be used. For your own interest, the following article does a good job discussing some of the available methods: https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4. Note that the term *imputation* refers to the process of filling in missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the *Age* attribute, we will fill in the missing values with a trivial method. The missing values will be filled with the mean age of passengers that contain a non-null age value. Although this will likely cause issues, such as making the algorithm learn inaccurate patterns from the mean age values, this is one of many trival approaches to filling in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataframe by filling in all missing age values as the mean of existing age values.\n",
    "X[\"Age\"].fillna(X[\"Age\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the *Embarked* attribute, we will do a little more investigation as to what the values should be. Since there are only two missing values and there are three available options for those values, we will manually select which value to assign to the rows missing the values. Below we view the means for all of the numerical attributes of the dataset, for each of the three possible *Embarked* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Embarked equals S:\n",
      "      PassengerId    Pclass        Age     SibSp     Parch       Fare\n",
      "mean    449.52795  2.350932  29.480855  0.571429  0.413043  27.079812\n",
      "\n",
      "When Embarked equals C:\n",
      "      PassengerId    Pclass        Age     SibSp     Parch       Fare\n",
      "mean   445.357143  1.886905  30.562419  0.386905  0.363095  59.954144\n",
      "\n",
      "When Embarked equals Q:\n",
      "      PassengerId    Pclass        Age     SibSp     Parch      Fare\n",
      "mean   417.896104  2.909091  29.113724  0.428571  0.168831  13.27603\n"
     ]
    }
   ],
   "source": [
    "# Isolate the rows for each possible value of Embarked (S, C, Q)\n",
    "# Get the mean values when equal to S\n",
    "df_embarked_S = X.loc[X[\"Embarked\"] == 'S']\n",
    "print(\"When Embarked equals S:\")\n",
    "print(df_embarked_S.describe().loc[['mean']])\n",
    "# Get the mean values when equal to C\n",
    "df_embarked_C = X.loc[X[\"Embarked\"] == 'C']\n",
    "print(\"\\nWhen Embarked equals C:\")\n",
    "print(df_embarked_C.describe().loc[['mean']])\n",
    "# Get the mean values when equal to Q\n",
    "df_embarked_Q = X.loc[X[\"Embarked\"] == 'Q']\n",
    "print(\"\\nWhen Embarked equals Q:\")\n",
    "print(df_embarked_Q.describe().loc[['mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take one more look at the rows with missing *Embarked* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                       Name     Sex  \\\n",
       "61            62       1                        Icard, Miss. Amelie  female   \n",
       "829          830       1  Stone, Mrs. George Nelson (Martha Evelyn)  female   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "61   38.0      0      0  113572  80.0   B28      NaN  \n",
       "829  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the rows with missing Embarked values again\n",
    "X[X['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the two above rows contain mostly similar data, it is safe to say that they will be assigned the same *Embarked* values. When comparing the values in these rows to the mean values seen above, it can be seen that when *Embarked* equals C, the means of all attributes (except the PassengerId, which is meaningless) are closest to the attribute values found from both of these rows. Therefore we will assign the value C to the *Embarked* attribute of the above two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NaN values for the Embarked column with the value 'C'\n",
    "X[\"Embarked\"].fillna('C', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q2 - 2 marks**   \n",
    "Imagine that we want to fill the missing values for the *Age* and *Embarked* attributes via another method. Propose one unique method to fill the missing values (can be trivial or complex) for the *Age* attribute and another unique method to fill the missing values for the *Embarked* attribute. Answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Q2       \n",
    "Computing the overall mean, median or mode is a very basic imputation method. It is very fast, but has clear disadvantages. One disadvantage is that mean imputation reduces variance in the dataset. Besides, interpolation and extrapolation are also good methods to fill in missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The missing values of \"Age\" will be filled with the median age of passengers that contain a non-null age value\n",
    "X[\"Age\"].fillna(X[\"Age\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The missing values of \"Embarked\" will be filled with the median of the value C to the Embarked attribute of the two rows that\n",
    "#had  a null Embarked value\n",
    "X[\"Embarked\"].fillna(df_embarked_C.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before selecting which features to use, we will convert the categorical data within the *Sex* and *Embarked* columns to be numerical. This will be done via One-Hot-Encoding, where each possible categorical value for an attribute is made to be its own attribute. Then, only one of these three attributes will contain the value 1 for a row, where the others contain 0. In the next notebook we will explore the OneHotEncoder provided by sklearn, but we will handle this manually with pandas for this notebook (via the *get_dummies* function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical values stored within the Sex column to be numerical via One-Hot-Encoding\n",
    "X = pd.concat([X, pd.get_dummies(X['Sex'], prefix='Sex')], axis=1)\n",
    "# Drop the original column\n",
    "X.drop(['Sex'], axis=1, inplace=True)\n",
    "# Convert the categorical values stored within the Embarked column to be numerical via One-Hot-Encoding\n",
    "X = pd.concat([X, pd.get_dummies(X['Embarked'], prefix='Embarked')], axis=1)\n",
    "# Drop the original column\n",
    "X.drop(['Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a final look at the first 5 entries in our dataset. Look at how the columns differ from the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_female  Sex_male  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN           0         1   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85           1         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN           1         0   \n",
       "3  35.0      1      0            113803  53.1000  C123           1         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN           0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feature selection and defining the train and validation sets**    \n",
    "\n",
    "With the data ready to be used, we will now select the features that we will be working with and define the training and validation sets from the available data. For our feature selection we will simply be selecting all non-null attributes except for the *PassengerId*, *Ticket* and *Name*.   \n",
    "\n",
    "The PassengerId is a unique number for each passenger and therefore cannot provide any useful patterns regarding the target class values. The names are also unlikely to provide any insight as to whether a passenger did or did not survive.    \n",
    "\n",
    "Although we can modify the *Name* attribute to be a numerical value based on the numebr of letters in the name (perhaps names with more alphabet letters had a higher survival rate), we will not do this since it is an illogical line of thought for this problem.     \n",
    "\n",
    "Ticket is a value that does not seem to provide any useful information either. Therefore we will not use it.\n",
    "\n",
    "Let us look at the remaining attributes with null values after our data cleaning to see what will else will not be selected as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Sex_female       0\n",
       "Sex_male         0\n",
       "Embarked_C       0\n",
       "Embarked_Q       0\n",
       "Embarked_S       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at what is null\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all attribtues except for *Cabin* contain no missing values. Although *Cabin* is important, we will exclude it since we did not properly clean it and majority of the data is missing a value. Although we can skip any rows that do not contain a *Cabin* value or can assign an 'unknown' value to missing values, there are too many missing values for this to be reasonable.    \n",
    "\n",
    "For the rest of the attributes, although we may benefit from combining some similar attributes (such as Parch and SibSp), we will use them as is since they are characteristics that can provide insight into whether a passenger did or did not survive.       \n",
    "\n",
    "For example, perhaps more females survived than males or perhaps younger passengers survived more frequently than older passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of attributes to use as features for the algorithms.\n",
    "featureSet = ['Pclass', 'Sex_female', 'Sex_male', 'Age', 'SibSp', \n",
    "              'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataframe to only contain the desired variables\n",
    "X = X[featureSet].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the features selected, we will now split the data into a training and validation set from the available data. Since we do not have the explicit testing set's class values (but do have a testing set), the test set produced by scikit-learn will be used to validate whether the learning appears to be successful. This is considered the validation set despite the name from sklearn's function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "# split the large dataset into train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=2)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex_female  Sex_male   Age  SibSp  Parch     Fare  Embarked_C  \\\n",
       "30        1           0         1  40.0      0      0  27.7208           1   \n",
       "10        3           1         0   4.0      1      1  16.7000           0   \n",
       "873       3           0         1  47.0      0      0   9.0000           0   \n",
       "182       3           0         1   9.0      4      2  31.3875           0   \n",
       "876       3           0         1  20.0      0      0   9.8458           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "30            0           0  \n",
       "10            0           1  \n",
       "873           0           1  \n",
       "182           0           1  \n",
       "876           0           1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the training set\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex_female  Sex_male   Age  SibSp  Parch     Fare  Embarked_C  \\\n",
       "707       1           0         1  42.0      0      0  26.2875           0   \n",
       "37        3           0         1  21.0      0      0   8.0500           0   \n",
       "615       2           1         0  24.0      1      2  65.0000           0   \n",
       "169       3           0         1  28.0      0      0  56.4958           0   \n",
       "68        3           1         0  17.0      4      2   7.9250           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "707           0           1  \n",
       "37            0           1  \n",
       "615           0           1  \n",
       "169           0           1  \n",
       "68            0           1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the validation set\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluation techniques**    \n",
    "\n",
    "Later on we will be using more evaluation techniques to better evaluate the performance of the models. For now, we will define functions to calculate the *Precision*, *Recall*, and *Accuracy* metrics. All of these were discussed in the previous notebook.    \n",
    "\n",
    "The *Accuracy* represents what percentage of classifications the model correctly made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(actualTags, predictions, classOfInterest):\n",
    "    '''\n",
    "    Calculates the precision for a specific class, given the ground truth and predicted values.\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == classOfInterest and actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / np.count_nonzero(predictions == classOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actualTags, predictions, classOfInterest):\n",
    "    '''\n",
    "    Calculates the recall for a specific class, given the ground truth and predicted values.\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == classOfInterest and actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / np.count_nonzero(actualTags == classOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actualTags, predictions):\n",
    "    '''\n",
    "    Calculates the average number of correct predictions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: What the model predicts\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of calculating accuracy\n",
    "accuracy([0, 1, 1, 1, 0], [1, 1, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Naive Bayes**    \n",
    "\n",
    "With the data preprocessed and several evaluation functions defined, we are now ready to use some Machine Learning algorithms to perform the predictions of whether or not a passenger survived on the Titanic.    \n",
    "\n",
    "The first approach that we will use is the Naive Bayes algorithm provided by scikit-learn. This will be a very similar process to what you have done in notebook 4. You will train the model by calling the *fit* function and will retrieve predictions from the model by calling the *predict* function. Unlike last notebook, we already have all of our data preprocessed as numerical features within a pandas dataframe, with the class labels as numpy arrays (y_train and y_val). Thus we will not need to perform any transformations, such as those that were performed in notebook 3.  \n",
    "\n",
    "The first task is to train the model with the .fit() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the training set by calling the .fit() function\n",
    "# X_train contains the features used to train the model\n",
    "# y_train contains the class labels for the samples from X_train\n",
    "clf_nb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get then view how the algorithm performs when predicting the samples in the training set through the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the first ten actual values to the predicted values:\n",
      "[0 1 0 0 0 0 0 1 1 0]\n",
      "[0 1 0 1 0 0 0 0 0 0]\n",
      "Calculating the total accuracy for the training set:\n",
      "0.6980337078651685\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "# Print the first ten class labels for the training set\n",
    "print(y_train[0:10])\n",
    "# Predict whether the passengers did or did not survive the Titanic on the training set\n",
    "nb_train_predictions = clf_nb.predict(X_train)\n",
    "# Print the first ten predictions\n",
    "print(nb_train_predictions[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train, nb_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that after being trained, the model can correctly predict just under 70% of all samples from the training set. But how well does it perform on the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q3 - 3 marks**   \n",
    "Following the example provided above, obtain the predictions from the Naive Bayes model on the entire validation set (X_val, y_val) and print the precision, recall, and accuracy for the validation set (for both classes, 1 and 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision when class = 0:  0.6535433070866141\n",
      "Precision when class = 1:  0.6730769230769231\n",
      "Recall when class = 0:  0.83\n",
      "Recall when class = 1:  0.4430379746835443\n",
      "Accuracy:  0.659217877094972\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Get the predictions for the validation set\n",
    "nb_val_predictions = clf_nb.predict(X_val)\n",
    "# Retrieve and print the precision values for class 1 and class 0\n",
    "print(\"Precision when class = 0: \", precision(y_val, nb_val_predictions, 0))\n",
    "print(\"Precision when class = 1: \", precision(y_val, nb_val_predictions, 1))\n",
    "# Retrieve and print the recall values for class 1 and class 0\n",
    "print(\"Recall when class = 0: \", recall(y_val, nb_val_predictions, 0))\n",
    "print(\"Recall when class = 1: \", recall(y_val, nb_val_predictions, 1))\n",
    "# Retrieve and print the accuracy for the model\n",
    "print(\"Accuracy: \", accuracy(y_val, nb_val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Logistic Regression**    \n",
    "\n",
    "With the predictions and data obtained for the Naive Bayes Machine Learning algorithm, we will try using another Machine Learning algorithm that may or may not perform better than the Naive Bayes approach. Specifically, we will use the Logistic Regression Machine Learning algorithm to predict who did and did not survive on the Titanic.    \n",
    "\n",
    "Since the Logistic Regression algorithm that we will be using also comes from scikit-learn, the general process will be nearly identical to what we have done for the Naive Bayes classifier. The main difference is that we will now be using a different algorithm that contains some options that we will need to set. All of the details of possible ways to tune the Logistic Regression model are available [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).     \n",
    "\n",
    "We will first initialize and train the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the training set by calling the .fit() function\n",
    "# X_train contains the features used to train the model\n",
    "# y_train contains the class labels for the samples from X_train\n",
    "clf_lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will view how the model performs on the training data to get an idea as to how the training went. Since we trained on this data, we will hopefully have strong results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the first ten actual values to the predicted values:\n",
      "[0 1 0 0 0 0 0 1 1 0]\n",
      "[0 1 0 0 0 0 0 1 0 0]\n",
      "Calculating the total accuracy for the training set:\n",
      "0.8103932584269663\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "# Print the first ten class labels for the training set\n",
    "print(y_train[0:10])\n",
    "# Predict whether the passengers did or did not survive the Titanic on the training set\n",
    "lr_train_predictions = clf_lr.predict(X_train)\n",
    "# Print the first ten predictions\n",
    "print(lr_train_predictions[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train, lr_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q4 - 3 marks**   \n",
    "Following the example provided above, obtain the predictions from the Logistic Regression model on the validation set (X_val, y_val) and print the precision, recall, and accuracy for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision when class = 0:  0.7583333333333333\n",
      "Precision when class = 1:  0.847457627118644\n",
      "Recall when class = 0:  0.91\n",
      "Recall when class = 1:  0.6329113924050633\n",
      "Accuracy:  0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Get the predictions for the validation set\n",
    "lr_val_predictions = clf_lr.predict(X_val)\n",
    "# Retrieve and print the precision values for class 1 and class 0\n",
    "print(\"Precision when class = 0: \", precision(y_val, lr_val_predictions, 0))\n",
    "print(\"Precision when class = 1: \", precision(y_val, lr_val_predictions, 1))\n",
    "# Retrieve and print the recall values for class 1 and class 0\n",
    "print(\"Recall when class = 0: \", recall(y_val, lr_val_predictions, 0))\n",
    "print(\"Recall when class = 1: \", recall(y_val, lr_val_predictions, 1))\n",
    "# Retrieve and print the accuracy for the model\n",
    "print(\"Accuracy: \", accuracy(y_val, lr_val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. More evaluation techniques**    \n",
    "\n",
    "Now that you have trained and tested the models above, you will define two additional evaluation methods. The first will be the Micro-average on precisions and the second will be the Macro-average on precisions. Definitions for these can be found in your course material.    \n",
    "\n",
    "Although we can also define the Micro- and Macro-averages on recalls, we will not do that for this notebook to avoid having too many evaluation metrics to consider. In reality, each dataset will have evaluation criteria that are more and less important to evaluating the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5 - 2 marks**   \n",
    "In the cell below, complete the definition of the micro_precision_average function. You must use only the parameters provided and cannot use any functionality from scikit-learn's library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def micro_precision_average(actualTags, predictions, class1, class2):\n",
    "    '''\n",
    "    Calculates the Micro-average on precisions. \n",
    "        - actualTags: The ground truth\n",
    "        - predictions: The predicted class values\n",
    "        - class1: The value of the first class\n",
    "        - class2: The value of the second class\n",
    "    '''\n",
    "    # micro_precision_average = (TP_c1 + TP_c2)/(TP_c1 + FP_c1 + TP_c2 + FP_c2)\n",
    "    class1_totalFound = 0\n",
    "    class2_totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == class1 and predictions[i] == class1):\n",
    "            class1_totalFound += 1  #TP_c1\n",
    "        elif (actualTags[i] == class2 and predictions[i] == class2):\n",
    "            class2_totalFound += 1  #TP_c2\n",
    "            \n",
    "    class1_predictions = 0\n",
    "    class2_predictions = 0\n",
    "    for j in range(len(predictions)):\n",
    "        if predictions[j] == class1:\n",
    "            class1_predictions +=1\n",
    "        else:\n",
    "            class2_predictions +=1\n",
    "            \n",
    "    return (class1_totalFound + class2_totalFound) / (class1_predictions + class2_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q6 - 2 marks**   \n",
    "In the cell below, complete the definition of the macro_precision_average function. You must use only the parameters provided and cannot use any functionality from scikit-learn's library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def macro_precision_average(actualTags, predictions, class1, class2):\n",
    "    '''\n",
    "    Calculates the Macro-average on precisions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: The predicted class values\n",
    "        - class1: The value of the first class\n",
    "        - class2: The value of the second class\n",
    "    '''\n",
    "    PreC_c1 = precision(actualTags, predictions, class1)\n",
    "    PreC_c2 = precision(actualTags, predictions, class2)\n",
    "    \n",
    "    return (PreC_c1 + PreC_c2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q7 - 2 marks**   \n",
    "To test these evaluation functions, evaluate the Micro- and Macro-averages on the precisions from your testing on the validation set with both the Naive Bayes and Logistic Regression models. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Naive Bayes:\n",
      "Micro Precision Average:  0.659217877094972\n",
      "Macro Precision Average:  0.6633101150817686\n",
      "For Logistic Regression:\n",
      "Micro Precision Average:  0.7877094972067039\n",
      "Macro Precision Average:  0.8028954802259887\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "print(\"For Naive Bayes:\")\n",
    "print(\"Micro Precision Average: \", micro_precision_average(y_val, nb_val_predictions, 1, 0))\n",
    "print(\"Macro Precision Average: \", macro_precision_average(y_val, nb_val_predictions, 1, 0))\n",
    "\n",
    "print(\"For Logistic Regression:\")\n",
    "print(\"Micro Precision Average: \", micro_precision_average(y_val, lr_val_predictions, 1, 0))\n",
    "print(\"Macro Precision Average: \", macro_precision_average(y_val, lr_val_predictions, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Discussion**    \n",
    "\n",
    "As with all Machine Learning experiments, we must use the data obtained to understand which model is better and why. In this scenario we have the precision, recall, accuracy, micro-average, and macro-average values. Below is a discussion question separated into sections for you to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q8 (a) - 2 marks**   \n",
    "Copy the outputs for the precision, recall, accuracy, micro-average, and macro-average obtained for both models in the table below (only from the validation tests). Each value goes into the corresponding <td\\></td\\> tag. For each evaluation approach, mention which Machine Learning model provides the better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:     \n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><strong>Naive Bayes</strong></td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "        <td><strong>Better Model</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=0)</strong></td>\n",
    "        <td>0.6535433070866141</td>\n",
    "        <td>0.7583333333333333</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=1)</strong></td>\n",
    "        <td>0.6730769230769231</td>\n",
    "        <td>0.847457627118644</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=0)</strong></td>\n",
    "        <td>0.83</td>\n",
    "        <td>0.91</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=1)</strong></td>\n",
    "        <td>0.4430379746835443</td>\n",
    "        <td>0.6329113924050633</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Accuracy</strong></td>\n",
    "        <td>0.659217877094972</td>\n",
    "        <td>0.7877094972067039</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Micro Average Precision</strong></td>\n",
    "        <td>0.659217877094972</td>\n",
    "        <td>0.7877094972067039</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Macro Average Precision</strong></td>\n",
    "        <td>0.6633101150817686</td>\n",
    "        <td>0.8028954802259887</td>\n",
    "        <td>Logistic Regression</td>\n",
    "    </tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q8 (b) - 2 marks**   \n",
    "Based on your results, which model performs better at predicting whether a passenger does or does not survive on the Titanic? Justify your answer.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:     \n",
    "Precision means the percentage of the results which are relevant. On the other hand, recall refers to the percentage of total relevant results correctly classified by the algorithm. Looking at values in the table (Q8-a), The Logistic Regrestion method demosntrated higher precision and recall values for both caless in comparison to the Naive Bayes method. \n",
    "\n",
    "Accuracy can be defined as the fraction of predictions that the model got right. Looking at values in the table (Q8-a), The Logistic Regrestion method demosntrated higher accuracy value in comparison to the Naive Bayes method.\n",
    "\n",
    "Based on arguments above, the Logistic Regreshion method performs better at predicting whether a passenger does or does not survive on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Balancing the class distribution**    \n",
    "\n",
    "As mentioned at the beginning of the notebook, this dataset contains more passengers that did not survived on the Titanic than those who did survive. This results in a class imbalance where the majority class (0) contains more instances than the minority class (1). There are many methods of handling this problem. One method is to simply take the minority class and, through some method, produce more instances of that class. For example, a trivial method could be to randomly select a number instances and duplicate them to match the number of instances from the majority class. This concept is called *oversampling*. You can also remove instances from the majority class to balance the class distribution (called *undersampling*).    \n",
    "\n",
    "For this notebook, oversampling will be performed via imblearn's implementation of a technique called SMOTE. Understanding SMOTE is beyond the scope of this notebook, but more information can be found [here](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/). The important thing to understand is that the number of instances for each class value will be the same by artificially creating new instances of passengers who survived from the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SMOTE instance\n",
    "smote = SMOTE(random_state=0, sampling_strategy=\"minority\")\n",
    "# Retrieve the oevrsampled data\n",
    "X_os, y_os = smote.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the oversampled dataset is now defined within X_os and y_os, not X and y. We will be using these values for the remainder of the notebook. Below we now look at how many instances in our new dataset contain the class 0 and how many contain the class 1. These values are now balanced when compared to the plot shown in section 1 of this notebook. Note that X_os is now a numpy array rather than a dataframe due to this conversion. This changes nothing regarding how we use it, but changes the method of plotting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 contains 549 instances.\n",
      "1 contains 549 instances.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of instances for each class\n",
    "class_names, totals = np.unique(y_os, return_counts=True)\n",
    "print(str(class_names[0]) + \" contains \" + str(totals[0]) + \" instances.\")\n",
    "print(str(class_names[1]) + \" contains \" + str(totals[1]) + \" instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the oversampled dataset, we will now define our new train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 10)\n",
      "(220,)\n"
     ]
    }
   ],
   "source": [
    "# split the large dataset into train and test\n",
    "X_train_os, X_val_os, y_train_os, y_val_os = train_test_split(X_os, y_os, test_size = 0.2, random_state=2)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train_os.shape)\n",
    "print(y_val_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this all defined, we will now train and test a new Naive Bayes and Logistic Regression model, evaluate the models, and determine whether the oversampling provided better results than without the oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 - 10 marks total**   \n",
    "Repeat the Machine Learning experiment performed throughout the previous sections on the new oversampled data. Ensure that you use the appropriate names (***do not forget the _os in the names*** to avoid incorrect solutions).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 (a) - 3 marks**   \n",
    "Train, test, and evaluate the validation set (with all evaluation metrics) with a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** For the training set ***\n",
      "Comparing the first ten actual values to the predicted values:\n",
      "[1 0 1 0 1 0 1 1 1 0]\n",
      "[0 0 0 1 0 1 0 0 1 0]\n",
      "Calculating the total accuracy for the training set:\n",
      "0.6446469248291572\n",
      "\n",
      "*** For the validation set ***\n",
      "Precision when class = 0:  0.5874125874125874\n",
      "Precision when class = 1:  0.7662337662337663\n",
      "Recall when class = 0:  0.8235294117647058\n",
      "Recall when class = 1:  0.5\n",
      "Accuracy:  0.65\n",
      "Micro Precision Average:  0.65\n",
      "Macro Precision Average:  0.6768231768231768\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q9 (a)\n",
    "# Train the model with the .fit() function\n",
    "clf_nb_os = MultinomialNB().fit(X_train_os, y_train_os)\n",
    "\n",
    "# Test the model with the train data\n",
    "print('*** For the training set ***')\n",
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "print(y_train_os[0:10])\n",
    "nb_train_predictions_os = clf_nb_os.predict(X_train_os)\n",
    "print(nb_train_predictions_os[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train_os, nb_train_predictions_os))\n",
    "\n",
    "# Evaluate the model with the validation set\n",
    "print('\\n*** For the validation set ***')\n",
    "nb_val_predictions_os = clf_nb_os.predict(X_val_os)\n",
    "print(\"Precision when class = 0: \", precision(y_val_os, nb_val_predictions_os, 0))\n",
    "print(\"Precision when class = 1: \", precision(y_val_os, nb_val_predictions_os, 1))\n",
    "print(\"Recall when class = 0: \", recall(y_val_os, nb_val_predictions_os, 0))\n",
    "print(\"Recall when class = 1: \", recall(y_val_os, nb_val_predictions_os, 1))\n",
    "print(\"Accuracy: \", accuracy(y_val_os, nb_val_predictions_os))\n",
    "print(\"Micro Precision Average: \", micro_precision_average(y_val_os, nb_val_predictions_os, 1, 0))\n",
    "print(\"Macro Precision Average: \", macro_precision_average(y_val_os, nb_val_predictions_os, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 (b) - 3 marks**   \n",
    "Train, test, and evaluate the validation set (with all evaluation metrics) with a Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** For the training set ***\n",
      "Comparing the first ten actual values to the predicted values:\n",
      "[1 0 1 0 1 0 1 1 1 0]\n",
      "[0 0 0 0 1 0 1 1 1 1]\n",
      "Calculating the total accuracy for the training set:\n",
      "0.8189066059225513\n",
      "\n",
      "*** For the validation set ***\n",
      "Precision when class = 0:  0.8035714285714286\n",
      "Precision when class = 1:  0.8888888888888888\n",
      "Recall when class = 0:  0.8823529411764706\n",
      "Recall when class = 1:  0.8135593220338984\n",
      "Accuracy:  0.8454545454545455\n",
      "Micro Precision Average:  0.8454545454545455\n",
      "Macro Precision Average:  0.8462301587301587\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q9 (b)\n",
    "# Train the model with the .fit() function\n",
    "clf_lr_os = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1).fit(X_train_os, y_train_os)\n",
    "\n",
    "# Test the model with the train data\n",
    "print('*** For the training set ***')\n",
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "print(y_train_os[0:10])\n",
    "lr_train_predictions_os = clf_lr_os.predict(X_train_os)\n",
    "print(lr_train_predictions_os[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train_os, lr_train_predictions_os))\n",
    "\n",
    "# Evaluate the model with the validation set\n",
    "print('\\n*** For the validation set ***')\n",
    "lr_val_predictions_os = clf_lr_os.predict(X_val_os)\n",
    "print(\"Precision when class = 0: \", precision(y_val_os, lr_val_predictions_os, 0))\n",
    "print(\"Precision when class = 1: \", precision(y_val_os, lr_val_predictions_os, 1))\n",
    "print(\"Recall when class = 0: \", recall(y_val_os, lr_val_predictions_os, 0))\n",
    "print(\"Recall when class = 1: \", recall(y_val_os, lr_val_predictions_os, 1))\n",
    "print(\"Accuracy: \", accuracy(y_val_os, lr_val_predictions_os))\n",
    "print(\"Micro Precision Average: \", micro_precision_average(y_val_os, lr_val_predictions_os, 1, 0))\n",
    "print(\"Macro Precision Average: \", macro_precision_average(y_val_os, lr_val_predictions_os, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 (c) - 2 marks**   \n",
    "Compare the results between the above two experiments (from Q9 (a) and Q9 (b)), which model is better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><strong>Naive Bayes (oversampled)</strong></td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "        <td><strong>Better Model</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=0)</strong></td>\n",
    "        <td>0.5874125874125874</td>\n",
    "        <td>0.8035714285714286</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=1)</strong></td>\n",
    "        <td>0.7662337662337663</td>\n",
    "        <td>0.8888888888888888</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=0)</strong></td>\n",
    "        <td>0.8235294117647058</td>\n",
    "        <td>0.8823529411764706</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=1)</strong></td>\n",
    "        <td>0.5</td>\n",
    "        <td>0.8135593220338984</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Accuracy</strong></td>\n",
    "        <td>0.65</td>\n",
    "        <td>0.8454545454545455</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Micro Average Precision</strong></td>\n",
    "        <td>0.65</td>\n",
    "        <td>0.8454545454545455</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Macro Average Precision</strong></td>\n",
    "        <td>0.6768231768231768</td>\n",
    "        <td>0.8462301587301587</td>\n",
    "        <td>Logistic Regression (oversampled)</td>\n",
    "    </tr>    \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "Precision means the percentage of the results which are relevant. On the other hand, recall refers to the percentage of total relevant results correctly classified by the algorithm. Looking at values in the table (Q9-c), The Logistic Regrestion (oversampled) method demosntrated higher precision and recall values for both caless in comparison to the Naive Bayes (oversampled) method. \n",
    "\n",
    "Accuracy can be defined as the fraction of predictions that the model got right. Looking at values in the table (Q9-c), The Logistic Regrestion (oversampled) method demosntrated higher accuracy value in comparison to the Naive Bayes (oversampled) method.\n",
    "\n",
    "Based on arguments above, the Logistic Regreshion method performs better at predicting whether a passenger does or does not survive on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 (d) - 2 marks**   \n",
    "Does the model selected from Q9 (c) perform better or worse than the model selected in Q8 (b)? Does this mean that the oversampling helps the Machine Learning learn better or worse in this scenario? Justify your answer.    \n",
    "\n",
    "Note: There is no need to put all the data in another table (you certainly can if you would like to better organize it). Just provide the answers along with justifications as to why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression                                  Logistic Regression (oversampled)                        Better Model\n",
    "\n",
    "Precision (class=0)\t    0.7583333333333333\t         Precision (class=0)     0.8035714285714286         Logistic Regression(os)\n",
    "Precision (class=1)  \t0.847457627118644\t         Precision (class=1)     0.8888888888888888         Logistic Regression(os)\n",
    "Recall (class=0)\t    0.91\t                     Recall (class=0)\t     0.8823529411764706         Logistic Regression\n",
    "Recall (class=1)\t    0.6329113924050633\t         Recall (class=1)\t     0.8135593220338984         Logistic Regression(os)\n",
    "Accuracy\t            0.7877094972067039\t         Accuracy\t\t         0.8454545454545455         Logistic Regression(os)\n",
    "Micro Average Precision\t0.7877094972067039\t         Micro Average Precision 0.8454545454545455         Logistic Regression(os)\n",
    "Macro Average Precision\t0.8028954802259887\t         Macro Average Precision 0.8462301587301587         Logistic Regression(os)\n",
    "\n",
    "Summary: \n",
    "Based on data comparison above, it is obvious that Logistic Regression (oversampled) method has shown better performance in comparison to the Logistic Regression method. Oversampling definityl helped to reach the higher evaluation percantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) OPTIONAL - No marks**   \n",
    "If you are interested, you can try out other approaches to handling the class imbalance problem via methods available with [imblearn](https://imbalanced-learn.readthedocs.io/en/stable/api.html). Then you can compare these results to see which method works best for this problem based on how we have cleaned the data and selected the features.    \n",
    "\n",
    "You may also try working with the test data file to see what your outputs are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SIGNATURE:***\n",
    "My name is Fatemeh Soltani.\n",
    "My student number is 300139153.\n",
    "I certify being the author of this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
